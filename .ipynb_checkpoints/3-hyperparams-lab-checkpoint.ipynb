{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll use the California Housing dataset to train a decision tree and tune our hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the california housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by loading up our data and splitting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = fetch_california_housing()\n",
    "\n",
    "\n",
    "\n",
    "X = pd.DataFrame(X, columns = dataset['feature_names'])\n",
    "y = dataset['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our data into training and test data.  Let's take a look at the first few rows of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        float64\n",
       "HouseAge      float64\n",
       "AveRooms      float64\n",
       "AveBedrms     float64\n",
       "Population    float64\n",
       "AveOccup      float64\n",
       "Latitude      float64\n",
       "Longitude     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because all of our data is numeric, and we do not have any na values, we should be able to train our decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check the score on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999576"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)\n",
    "\n",
    "# 0.9999999999999576"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what really matters is how well we perform on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6218026389952888"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we don't do as well on the test set, but we still don't perform too poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters in SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can improve our model by tuning our hyperparameters.  We can do so by trying different `max_depth` between 1 and 50, and assessing the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeRegressor(max_depth = idx).fit(X_train, y_train) for idx in range(1, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [model.score(X_test, y_test) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So fitting our decision tree with this hyperparameter we find the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a24691e90>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "max_levs = list(range(1, 50))\n",
    "ax.scatter(max_levs, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that our model performs best when we have max levels of 11.  Let's train and score the model again, with a hyperparameter of 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808146299786579"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeRegressor(max_depth = 11)\n",
    "model.fit(X_train, y_train).score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that we slightly improve our score score by tuning our `max_depth` hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we practiced tuning the hyperparameter in a single decision tree.  We did so by looping through different values for our hyperparameter and then choosing the hyperparameter that results in the highest score on our holdout set.  In future lessons, we'll be using this same technique to choose our hyperparameters as we move to random forests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
