{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last lesson, we were introduced to a random forest.  We saw that with decision trees, we not only get a high degree of variation in the leafs of a tree, but also throughout the tree.  This is because a decision tree works sequentially, a split of a data at a higher level affects how the data will be split at lower levels.  It's also because decision tress happen to have very few assumptions about the data -- unlike say a linear model which assumes that the data fits some form of a line.  With a decision trees,Â we are working with a very flexible model and this gives us a wide degree of variation.\n",
    "\n",
    "This variance is a problem if using just one decision tree to make our predictions.  However, we can reduce our variance by fitting many different trees, and then taking the average of the predictions.  This is the main idea behind a random forest.  In this lesson, we'll see some other ideas of a random forest.  There will be various details, but the main idea behind a random forest is the following: \n",
    "\n",
    "Our variation of in our models is good, even encouraged.  Because different kinds of models means the models can discover different patterns in the data.  And to correct for the model fitting to noise, we aggregate the models reducing the effect of random patterns which are unlikely to happen again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson, let's work with the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "dataset = load_diabetes()\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Forest from the Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first idea of random forests is one that we already know.  With random forests we are averaging the predictions from a number of decision trees.  We can see this directly by loading up our random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators = 10)\n",
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we fit our random forest regressor, our regressors comes with a new attribute, called `estimators`.  We can see that these are the decision trees that make up our random forest.  Let's just look at the first two of our estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=1049688868, splitter='best'),\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=315774931, splitter='best')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = rfr.estimators_\n",
    "len(estimators)\n",
    "# 10\n",
    "estimators[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tree_predictions = np.hstack([estimator.predict(X_test[:1, :]) for estimator in rfr.estimators_])\n",
    "tree_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we made ten different predictions one for each tree.  And we just take the average to get the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is exactly what we get from our random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89.5])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.predict(X_test[:1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sampling the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the tree predictions, we'll see that we received different predictions on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{69.0, 135.0, 144.0, 154.0}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tree_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now how would we train ten predictions if we are training our decision trees on exactly the same data, and each decision tree is following the same rules?  We can't.  If a random forest were to train ten decision trees on exactly the same data, each tree would wind up exactly the same, and each would fit the random variation in the data the same way.  \n",
    "\n",
    "This doesn't help reduce our error of variance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that there is variation among the fitted trees, the random forest randomly selects a subset of the features to potentially split on.  It randomly re-selects the features to split on at *each split* of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we look at the first two trees trained on our random forest, we see that they each have a different root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "\n",
    "estimator_1 = estimators[0]\n",
    "graph_1 = Source(tree.export_graphviz(estimator_1, out_file=None,\n",
    "                                    feature_names=dataset['feature_names'], \n",
    "                                    max_depth=1))\n",
    "\n",
    "\n",
    "\n",
    "estimator_2 = estimators[1]\n",
    "graph_2 = Source(tree.export_graphviz(estimator_2, out_file=None,\n",
    "                                    feature_names=dataset['feature_names'], \n",
    "                                    max_depth=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"244pt\" viewBox=\"0.00 0.00 304.00 244.00\" width=\"304pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 240)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-240 300,-240 300,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" points=\"200.2133,-236 93.7867,-236 93.7867,-172 200.2133,-172 200.2133,-236\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-220.8\">bmi &lt;= 0.012</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-206.8\">mse = 6149.82</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-192.8\">samples = 190</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-178.8\">value = 150.845</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" points=\"138.2133,-136 31.7867,-136 31.7867,-72 138.2133,-72 138.2133,-136\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-120.8\">s5 &lt;= 0.017</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-106.8\">mse = 4212.202</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-92.8\">samples = 123</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-78.8\">value = 122.187</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>0-&gt;1</title>\n",
       "<path d=\"M127.0415,-171.8089C121.6763,-163.1553 115.8035,-153.683 110.1937,-144.635\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"113.1652,-142.7855 104.9211,-136.1308 107.2159,-146.4741 113.1652,-142.7855\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99.2118\" y=\"-156.2701\">True</text>\n",
       "</g>\n",
       "<!-- 242 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>242</title>\n",
       "<polygon fill=\"none\" points=\"263.2133,-136 156.7867,-136 156.7867,-72 263.2133,-72 263.2133,-136\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-120.8\">bmi &lt;= 0.072</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-106.8\">mse = 5052.863</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-92.8\">samples = 67</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-78.8\">value = 208.745</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;242 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>0-&gt;242</title>\n",
       "<path d=\"M167.2804,-171.8089C172.7322,-163.1553 178.6997,-153.683 184.3999,-144.635\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"187.3885,-146.4573 189.7576,-136.1308 181.4659,-142.726 187.3885,-146.4573\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.2917\" y=\"-156.3105\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" points=\"54,-36 0,-36 0,0 54,0 54,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"27\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1-&gt;2</title>\n",
       "<path d=\"M63.4029,-71.9768C57.3791,-63.0449 50.8986,-53.4359 45.0989,-44.8363\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"47.8423,-42.6445 39.3491,-36.3108 42.0388,-46.5585 47.8423,-42.6445\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 185 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>185</title>\n",
       "<polygon fill=\"none\" points=\"126,-36 72,-36 72,0 126,0 126,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;185 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>1-&gt;185</title>\n",
       "<path d=\"M90.2131,-71.9768C91.5906,-63.515 93.067,-54.4455 94.4089,-46.2023\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"97.8669,-46.7432 96.0192,-36.3108 90.9578,-45.6184 97.8669,-46.7432\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 243 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>243</title>\n",
       "<polygon fill=\"none\" points=\"224,-36 170,-36 170,0 224,0 224,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 242&#45;&gt;243 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>242-&gt;243</title>\n",
       "<path d=\"M205.1593,-71.9768C203.8802,-63.515 202.5092,-54.4455 201.2631,-46.2023\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"204.7233,-45.6753 199.7679,-36.3108 197.802,-46.7216 204.7233,-45.6753\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 342 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>342</title>\n",
       "<polygon fill=\"none\" points=\"296,-36 242,-36 242,0 296,0 296,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 242&#45;&gt;342 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>242-&gt;342</title>\n",
       "<path d=\"M231.9694,-71.9768C238.1616,-62.9509 244.8282,-53.2335 250.7751,-44.5651\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"253.6669,-46.5368 256.438,-36.3108 247.8947,-42.5768 253.6669,-46.5368\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(SVG(graph_1.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"244pt\" viewBox=\"0.00 0.00 304.00 244.00\" width=\"304pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 240)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-240 300,-240 300,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" points=\"200.2133,-236 93.7867,-236 93.7867,-172 200.2133,-172 200.2133,-236\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-220.8\">s5 &lt;= -0.003</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-206.8\">mse = 6299.741</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-192.8\">samples = 183</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-178.8\">value = 156.351</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"none\" points=\"138.2133,-136 31.7867,-136 31.7867,-72 138.2133,-72 138.2133,-136\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-120.8\">s3 &lt;= -0.016</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-106.8\">mse = 3220.838</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-92.8\">samples = 81</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-78.8\">value = 102.947</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>0-&gt;1</title>\n",
       "<path d=\"M127.0415,-171.8089C121.6763,-163.1553 115.8035,-153.683 110.1937,-144.635\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"113.1652,-142.7855 104.9211,-136.1308 107.2159,-146.4741 113.1652,-142.7855\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99.2118\" y=\"-156.2701\">True</text>\n",
       "</g>\n",
       "<!-- 152 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>152</title>\n",
       "<polygon fill=\"none\" points=\"263.2133,-136 156.7867,-136 156.7867,-72 263.2133,-72 263.2133,-136\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-120.8\">bmi &lt;= 0.018</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-106.8\">mse = 4634.723</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-92.8\">samples = 102</text>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-78.8\">value = 199.335</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;152 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>0-&gt;152</title>\n",
       "<path d=\"M167.2804,-171.8089C172.7322,-163.1553 178.6997,-153.683 184.3999,-144.635\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"187.3885,-146.4573 189.7576,-136.1308 181.4659,-142.726 187.3885,-146.4573\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.2917\" y=\"-156.3105\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" points=\"54,-36 0,-36 0,0 54,0 54,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"27\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>1-&gt;2</title>\n",
       "<path d=\"M63.4029,-71.9768C57.3791,-63.0449 50.8986,-53.4359 45.0989,-44.8363\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"47.8423,-42.6445 39.3491,-36.3108 42.0388,-46.5585 47.8423,-42.6445\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 39 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>39</title>\n",
       "<polygon fill=\"none\" points=\"126,-36 72,-36 72,0 126,0 126,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;39 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>1-&gt;39</title>\n",
       "<path d=\"M90.2131,-71.9768C91.5906,-63.515 93.067,-54.4455 94.4089,-46.2023\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"97.8669,-46.7432 96.0192,-36.3108 90.9578,-45.6184 97.8669,-46.7432\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 153 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>153</title>\n",
       "<polygon fill=\"none\" points=\"224,-36 170,-36 170,0 224,0 224,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 152&#45;&gt;153 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>152-&gt;153</title>\n",
       "<path d=\"M205.1593,-71.9768C203.8802,-63.515 202.5092,-54.4455 201.2631,-46.2023\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"204.7233,-45.6753 199.7679,-36.3108 197.802,-46.7216 204.7233,-45.6753\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 258 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>258</title>\n",
       "<polygon fill=\"none\" points=\"296,-36 242,-36 242,0 296,0 296,-36\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269\" y=\"-13.8\">(...)</text>\n",
       "</g>\n",
       "<!-- 152&#45;&gt;258 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>152-&gt;258</title>\n",
       "<path d=\"M231.9694,-71.9768C238.1616,-62.9509 244.8282,-53.2335 250.7751,-44.5651\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"253.6669,-46.5368 256.438,-36.3108 247.8947,-42.5768 253.6669,-46.5368\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(SVG(graph_2.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first tree has a root node of `bmi` while the second tree has a root node of `s5`.  One possible reason why bmi is not the root node on each of the trees is that when considering the set of features for the root node of the second tree, bmi simply was not available at that split.  But then was available at the split of the data seen on the second level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify what percentage of the features to consider at each split by passing different values into the `max_features` argument.  The [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) specifies the following options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * If int, then consider max_features features at each split.\n",
    "> * If float, then max_features is a fraction and int(max_features * n_features) features are considered at each split.\n",
    "> * If âautoâ, then max_features=n_features.\n",
    "> * If âsqrtâ, then max_features=sqrt(n_features).\n",
    "> * If âlog2â, then max_features=log2(n_features).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Subsampling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two parts to sub-sampling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Subsample the data before creating each tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This idea is just what it sounds like.  Each tree of a random forest only trains on a subset of the training data.  This way, even if all of the features were trained on, we would get different trees.  This is because each tree would see different training data.\n",
    "\n",
    "In this first variation, every time a tree is selected a different subset of the data is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bootstrapping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bootstrapping** means that when we take a subsample the datset, we sample with replacement.  This is how it works. \n",
    "\n",
    "Say we have observations one through ten.  If we were just to take a subsample, then we would select five of the observations.  And each observation could only be selected once.  But when we sample with replacement, we select from the list of observations, but do not remove the selected observation from the pool of data we select from.  Let's bootstrap from our array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_thirteen = np.arange(1, 14)\n",
    "one_to_thirteen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9,  5,  1,  1,  9,  4, 13])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(21)\n",
    "np.random.choice(one_to_thirteen, 8, replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that we select numbers multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's pretend that these ten observations are our dataset.  Our first step is to train test split our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 11, 12])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(20)\n",
    "training = np.random.choice(one_to_thirteen, 10, replace = False)\n",
    "training.sort()\n",
    "test = np.setdiff1d(one_to_thirteen, training)\n",
    "test.sort()\n",
    "\n",
    "training\n",
    "# array([ 1,  2,  3,  5,  6,  7,  8,  9, 10, 13])\n",
    "test\n",
    "# array([ 4, 11, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, mimicking the procedure of a random forest, we subsample the data.  Let's say that we select sixty percent of our training set each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6,  7,  9, 10, 13],\n",
       "       [ 1,  2,  3,  6,  9, 10],\n",
       "       [ 3,  5,  6,  8,  9, 10],\n",
       "       [ 1,  3,  5,  7,  8, 10],\n",
       "       [ 1,  6,  7,  9, 10, 13]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "datasets = np.stack([np.random.choice(training, 6, replace = False) for num in range(0, 5)])\n",
    "datasets.sort(axis=1)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look closely at our datasets, notice that a couple of them are fairly similar.  The last and first one for example.  And the second and third rows share four of six datapoints.  This can be problematic because remember we want variation in our trees, as we want our trees to discover different patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sample our training set with replacement.  This is bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  8,  8, 10, 10, 13],\n",
       "       [ 2,  3,  5,  8,  9, 13],\n",
       "       [ 1,  1,  7,  7,  7, 13],\n",
       "       [ 2,  2,  5,  6,  9, 13],\n",
       "       [ 2,  5,  6,  8,  8,  9]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(23)\n",
    "datasets = np.stack([np.random.choice(training, 6, replace = True) for num in range(0, 5)])\n",
    "datasets.sort(axis=1)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a lot more variation in our data.  The last two rows do match on four datapoints.  But that is as close as we get.  We simply have a lot more variations in our data when we resample.  So bootstrapping allows to essentially put random weights on various datapoints, which allows us to construct different trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our random forest in sklearn, bootstrapping is the default behavior of a random forest.  If we wanted to turn bootstrapping off, we can pass through an argument of `bootstrap = False`.  (But we don't want to do that.)  With the default behavior, our random forest will sample with replacement before constructing each tree in the random forest.  This increases the variances of our trees.  However, we expect to reduce the variance error by aggregating our trees (and taking the mean of their predictions at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor(bootstrap = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Random Forest Top to Bottom](https://www.gormanalysis.com/blog/random-forest-from-top-to-bottom/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
